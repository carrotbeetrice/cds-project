{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np, pandas as pd, pickle, time, argparse\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "    ByteTensor = torch.cuda.ByteTensor\n",
    "else:\n",
    "    FloatTensor = torch.FloatTensor\n",
    "    LongTensor = torch.LongTensor\n",
    "    ByteTensor = torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyDialogueDataset(Dataset):\n",
    "    def __init__(self, split:str, path:str) -> None:\n",
    "        self.speakers, self.input_sequence, self.input_max_seq_length, self.act_labels, self.emotion_labels, self.train_id, self.test_id, self.valid_id = pickle.load(open(path, 'rb'))\n",
    "\n",
    "        if split == 'train':\n",
    "            self.keys = [x for x in self.train_id]\n",
    "        elif split == 'test':\n",
    "            self.keys = [x for x in self.test_id]\n",
    "        elif split == 'valid':\n",
    "            self.keys = [x for x in self.valid_id]\n",
    "\n",
    "        self.len = len(self.keys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        conv = self.keys[index]\n",
    "\n",
    "        return torch.LongTensor(self.input_sequence[conv]), \\\n",
    "                torch.FloatTensor([[1,0] if x=='0' else [0,1] for x in self.speakers[conv]]),\\\n",
    "                torch.FloatTensor([1]*len(self.act_labels[conv])), \\\n",
    "                torch.LongTensor(self.act_labels[conv]), \\\n",
    "                torch.LongTensor(self.emotion_labels[conv]), \\\n",
    "                self.input_max_seq_length[conv], \\\n",
    "                conv\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "\n",
    "class DailyDialoguePadCollate:\n",
    "\n",
    "    def __init__(self, dim=0):\n",
    "        self.dim = dim\n",
    "\n",
    "    def pad_tensor(self, vec, pad, dim):\n",
    "\n",
    "        pad_size = list(vec.shape)\n",
    "        pad_size[dim] = pad - vec.size(dim)\n",
    "        return torch.cat([vec, torch.zeros(*pad_size).type(torch.LongTensor)], dim=dim)\n",
    "\n",
    "    def pad_collate(self, batch):\n",
    "        \n",
    "        # find longest sequence\n",
    "        max_len = max(map(lambda x: x.shape[self.dim], batch))\n",
    "        \n",
    "        # pad according to max_len\n",
    "        batch = [self.pad_tensor(x, pad=max_len, dim=self.dim) for x in batch]\n",
    "        \n",
    "        # stack all\n",
    "        return torch.stack(batch, dim=0)\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        dat = pd.DataFrame(batch)\n",
    "        \n",
    "        return [self.pad_collate(dat[i]).transpose(1, 0).contiguous() if i==0 else \\\n",
    "                pad_sequence(dat[i]) if i == 1 else \\\n",
    "                pad_sequence(dat[i], True) if i < 5 else \\\n",
    "                dat[i].tolist() for i in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, ouput_size, filters, kernel_sizes, dropout) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels=embedding_dim, out_channels=filters, kernel_size=K) for K in kernel_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * filters, ouput_size)\n",
    "        self.feature_dim = ouput_size\n",
    "\n",
    "    def init_pretrained_embeddings_from_numpy(self, pretrained_word_vectors):\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(pretrained_word_vectors).float())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x, unmask):\n",
    "        num_utt, batch, num_words = x.size()\n",
    "\n",
    "        x = x.type(LongTensor) # (num_utt, batch, num_words)\n",
    "        x = x.view(-1, num_words) # (num_utt, batch, num_words) -> (num_utt * batch, num_words)\n",
    "        emb = self.embedding(x) # (num_utt * batch, num_words) -> (num_utt * batch, num_words, 300)\n",
    "        emb = emb.transpose(-2, -1).contiguous() # (num_utt * batch, num_words, 300) -> (num_utt * batch, 300, num_words)\n",
    "\n",
    "        convoluted = [F.relu(conv(emb)) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(c, c.size()).squeeze() for c in convoluted]\n",
    "        concated = torch.cat(pooled, 1)\n",
    "        features = F.relu(self.fc(self.dropout(concated))) # (num_utt * batch, 150) -> (num_utt * batch, 100)\n",
    "        features = features.view(num_utt, batch, -1) # (num_utt * batch, 100) -> (num_utt, batch, 100)\n",
    "        mask = unmask.unsqueeze(-1).type(FloatTensor) # (batch, num_utt) -> (batch, num_utt, 1)\n",
    "        mask = mask.transpose(0, 1) # (batch, num_utt, 1) -> (num_utt, batch, 1)\n",
    "        mask = mask.repeat(1, 1, self.feature_dim) # (num_utt, batch, 1) -> (num_utt, batch, 100)\n",
    "        features = (features * mask)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyDialogueModel(nn.Module):\n",
    "    def __init__(self, D_m, D_g, D_p, D_e, D_h,\n",
    "                 vocab_size, n_classes=7, embedding_dim=300, \n",
    "                 cnn_output_size=100, cnn_filters=50, cnn_kernel_sizes=(3,4,5), cnn_dropout=0.5,\n",
    "                 listener_state=False, context_attention='simple', D_a=100, dropout_rec=0.5,\n",
    "                 dropout=0.5, att2=True) -> None:\n",
    "        super().__init__()\n",
    "        self.cnn_feat_extractor = CNNFeatureExtractor(vocab_size, embedding_dim, cnn_output_size, cnn_filters, cnn_kernel_sizes, cnn_dropout)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18726, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv_pretrained = np.load(open('../data/dailydialog/glv_embedding_matrix', 'rb'), allow_pickle=True)\n",
    "vocab_size, embedding_dim = glv_pretrained.shape\n",
    "glv_pretrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzier = np.load(open(\"../data/dailydialog/tokenizer.pkl\", \"rb\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
